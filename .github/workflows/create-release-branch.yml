name: Create release branch

on:
  workflow_dispatch:
    # No inputs - version bump is AI-detected by Codex

permissions:
  contents: write
  pull-requests: write

jobs:
  create:
    runs-on: ubuntu-latest
    environment: release
    env:
      NX_DAEMON: "false"
      CODEX_OUTPUT: .codex-release/release-output.json

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Fail fast if env secret is not available
      - name: Ensure CODEX_OPENAI_KEY secret is set
        run: |
          if [ -z "${{ secrets.CODEX_OPENAI_KEY }}" ]; then
            echo "::error::CODEX_OPENAI_KEY (env: release) is not set. Add it under Settings → Environments → release → Secrets." >&2
            exit 1
          fi

      - name: Setup Node
        uses: actions/setup-node@v6
        with:
          node-version-file: ".nvmrc"
          cache: "yarn"
          registry-url: "https://registry.npmjs.org/"

      - name: Install deps
        run: yarn

      - name: Configure git user
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Get last release info
        id: last_release
        shell: bash
        run: |
          set -euo pipefail

          # Check for any release tags
          LAST_TAG=$(git tag --list "v*" --sort=-version:refname | head -n1 || echo "")

          if [ -n "$LAST_TAG" ]; then
            echo "last_tag=$LAST_TAG" >> "$GITHUB_OUTPUT"
            echo "is_first_release=false" >> "$GITHUB_OUTPUT"
            echo "Last release tag: $LAST_TAG"
          else
            FIRST_COMMIT=$(git rev-list --max-parents=0 HEAD)
            echo "last_tag=$FIRST_COMMIT" >> "$GITHUB_OUTPUT"
            echo "is_first_release=true" >> "$GITHUB_OUTPUT"
            echo "First release - using first commit as base: ${FIRST_COMMIT:0:8}"
          fi

      - name: Find affected projects
        id: affected
        shell: bash
        run: |
          set -euo pipefail

          BASE_REF="${{ steps.last_release.outputs.last_tag }}"

          # Get all publishable libs
          ALL_LIBS=$(node -e "
          const { execSync } = require('child_process');
          try {
            const out = execSync('npx nx show projects -p tag:scope:publishable --type lib --json', { encoding: 'utf8' });
            const arr = JSON.parse(out);
            process.stdout.write(arr.join(','));
          } catch (e) {
            process.stdout.write('');
          }
          ")

          if [ -z "$ALL_LIBS" ]; then
            echo "projects=" >> "$GITHUB_OUTPUT"
            echo "No publishable libraries found"
            exit 0
          fi

          echo "All publishable libs: $ALL_LIBS"

          # Get affected libs since last release
          AFFECTED=$(node -e "
          const { execSync } = require('child_process');
          try {
            const out = execSync('npx nx show projects --affected --base=\"${BASE_REF}\" --type lib --json', { encoding: 'utf8' });
            const arr = JSON.parse(out);
            process.stdout.write(arr.join(','));
          } catch (e) {
            process.stdout.write('');
          }
          ")

          # Filter to only publishable affected libs
          AFFECTED_PUBLISHABLE=$(node -e "
          const all = '$ALL_LIBS'.split(',').filter(Boolean);
          const affected = '$AFFECTED'.split(',').filter(Boolean);
          const intersection = all.filter(lib => affected.includes(lib));
          process.stdout.write(intersection.join(','));
          ")

          echo "projects=$AFFECTED_PUBLISHABLE" >> "$GITHUB_OUTPUT"

          if [ -n "$AFFECTED_PUBLISHABLE" ]; then
            echo "Affected publishable libs: $AFFECTED_PUBLISHABLE"
          else
            echo "No affected publishable libraries"
          fi

      - name: Stop if no affected projects
        if: steps.affected.outputs.projects == ''
        run: |
          echo "No affected projects to release."
          exit 0

      # ========================================
      # MCP Integration: Configure Codex home with MCP servers
      # ========================================
      - name: Prepare Codex home with MCP config
        id: mcp
        shell: bash
        run: |
          set -euo pipefail
          CODEX_HOME="${RUNNER_TEMP}/codex-home"
          mkdir -p "$CODEX_HOME"

          echo "Setting up Codex home with MCP servers..."

          cat > "$CODEX_HOME/config.toml" << 'EOF'
          [features]
          # Enable the Rust MCP client (needed for HTTP/OAuth MCP support)
          rmcp_client = true

          # --- Mintlify Documentation Server ---
          # Provides access to Mintlify documentation best practices
          [mcp_servers.mintlify_docs]
          url = "https://mintlify.com/docs/mcp"
          http_headers = { "X-MCP-Readonly" = "true" }
          startup_timeout_sec = 30
          tool_timeout_sec = 60
          EOF

          echo "✓ Codex home configured with MCP servers"
          echo "codex_home=${CODEX_HOME}" >> "$GITHUB_OUTPUT"
        env:
          RUNNER_TEMP: ${{ runner.temp }}

      - name: Prepare diff context for Codex
        id: ctx
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p .github/codex/prompts .codex-release

          BASE_REF="${{ steps.last_release.outputs.last_tag }}"
          PROJECTS="${{ steps.affected.outputs.projects }}"
          IS_FIRST="${{ steps.last_release.outputs.is_first_release }}"

          echo "Preparing diff context..."
          echo "Base ref: $BASE_REF"
          echo "Projects: $PROJECTS"
          echo "Is first release: $IS_FIRST"

          # Save context files for Codex
          echo "$BASE_REF" > .github/codex/prompts/base.txt
          echo "$PROJECTS" > .github/codex/prompts/projects.txt
          echo "$IS_FIRST" > .github/codex/prompts/is-first-release.txt

          # Get current versions for each affected project
          echo "Current versions:" > .github/codex/prompts/current-versions.txt
          IFS=',' read -ra LIBS <<< "$PROJECTS"
          for lib in "${LIBS[@]}"; do
            if [ -f "libs/$lib/package.json" ]; then
              VERSION=$(node -e "console.log(require('./libs/$lib/package.json').version || '0.0.0')")
              echo "$lib=$VERSION" >> .github/codex/prompts/current-versions.txt
            fi
          done

          # Generate unified diff for affected projects
          # Filter to source files only to reduce token usage
          git diff "$BASE_REF"...HEAD --unified=3 \
            -- \
            'libs/**/*.ts' \
            'libs/**/package.json' \
            ':!**/*.spec.ts' \
            ':!**/*.test.ts' \
            ':!**/__tests__/**' \
            > .github/codex/prompts/diff.patch || true

          DIFF_SIZE=$(wc -c < .github/codex/prompts/diff.patch || echo "0")
          echo "Diff size: $DIFF_SIZE bytes"

          # Commit list for context
          git log "$BASE_REF"...HEAD --pretty=format:'%H%x09%s' -n 50 > .github/codex/prompts/commits.txt || true

          # ISO date
          date -u +"%Y-%m-%d" > .github/codex/prompts/date.txt

      # ========================================
      # Single Codex call for version analysis + docs update
      # (Cannot run sequential Codex actions due to sudo restrictions)
      # ========================================
      - name: Run Codex for release analysis
        if: steps.affected.outputs.projects != ''
        id: codex
        uses: openai/codex-action@v1
        with:
          openai-api-key: ${{ secrets.CODEX_OPENAI_KEY }}
          codex-home: ${{ steps.mcp.outputs.codex_home }}
          prompt-file: .github/codex/prompts/analyze-release.md
          output-file: ${{ env.CODEX_OUTPUT }}
          model: "gpt-5.1-codex"
          output-schema-file: .github/codex/schemas/release-output.json
          codex-args: "--full-auto"

      - name: Apply version bumps and changelogs from Codex
        id: versions
        if: steps.affected.outputs.projects != ''
        shell: bash
        run: |
          set -euo pipefail

          echo "Applying version bumps and changelogs from Codex analysis..."

          if [ ! -f "${{ env.CODEX_OUTPUT }}" ]; then
            echo "::error::Codex output file not found"
            exit 1
          fi

          echo "Codex output:"
          cat "${{ env.CODEX_OUTPUT }}"

          # Parse Codex JSON output, update package.json files, and update changelogs
          RESULT=$(node << 'NODEJS_SCRIPT'
          const fs = require('fs');
          const output = JSON.parse(fs.readFileSync('${{ env.CODEX_OUTPUT }}', 'utf8'));
          const today = new Date().toISOString().split('T')[0];

          let maxVersion = '0.0.0';
          const bumpedProjects = [];
          const internalVersions = {};

          // Helper to increment patch version
          function bumpPatch(version) {
            const parts = version.split('.');
            if (parts.length < 3 || isNaN(parseInt(parts[2], 10))) {
              throw new Error('Invalid semantic version: ' + version);
            }
            parts[2] = String(parseInt(parts[2], 10) + 1);
            return parts.join('.');
          }

          // Helper to check if version is exact (no range specifier)
          function isExactVersion(version) {
            return /^\d+\.\d+\.\d+$/.test(version);
          }

          // Helper to generate changelog entry
          function generateChangelogEntry(version, changelog) {
            const categories = [
              { key: 'added', title: 'Added' },
              { key: 'changed', title: 'Changed' },
              { key: 'deprecated', title: 'Deprecated' },
              { key: 'removed', title: 'Removed' },
              { key: 'fixed', title: 'Fixed' },
              { key: 'security', title: 'Security' }
            ];

            let entry = '## [' + version + '] - ' + today + '\n';
            let hasContent = false;

            for (const cat of categories) {
              const items = changelog[cat.key] || [];
              if (items.length > 0) {
                entry += '\n### ' + cat.title + '\n\n';
                for (const item of items) {
                  entry += '- ' + item + '\n';
                }
                hasContent = true;
              }
            }

            return hasContent ? entry : null;
          }

          // Update per-library changelogs
          for (const proj of output.projects) {
            if (proj.bump !== 'none') {
              // Update package.json
              const pkgPath = 'libs/' + proj.name + '/package.json';
              const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
              pkg.version = proj.newVersion;
              fs.writeFileSync(pkgPath, JSON.stringify(pkg, null, 2) + '\n');
              console.error('Updated ' + proj.name + ' to ' + proj.newVersion + ' (' + proj.bump + '): ' + proj.reason);
              bumpedProjects.push(proj.name);
              internalVersions[proj.name] = proj.newVersion;

              // Track max version
              if (proj.newVersion.localeCompare(maxVersion, undefined, { numeric: true, sensitivity: 'base' }) > 0) {
                maxVersion = proj.newVersion;
              }

              // Update per-lib changelog
              const changelogPath = 'libs/' + proj.name + '/CHANGELOG.md';
              if (fs.existsSync(changelogPath) && proj.changelog) {
                const entry = generateChangelogEntry(proj.newVersion, proj.changelog);
                if (entry) {
                  let content = fs.readFileSync(changelogPath, 'utf8');
                  // Insert after ## [Unreleased] section
                  const unreleasedMatch = content.match(/## \[Unreleased\]\n*/);
                  if (unreleasedMatch) {
                    const insertPos = unreleasedMatch.index + unreleasedMatch[0].length;
                    content = content.slice(0, insertPos) + '\n' + entry + '\n' + content.slice(insertPos);
                  } else {
                    // No Unreleased section, insert after header
                    const headerEnd = content.indexOf('\n\n') + 2;
                    content = content.slice(0, headerEnd) + '## [Unreleased]\n\n' + entry + '\n' + content.slice(headerEnd);
                  }
                  fs.writeFileSync(changelogPath, content);
                  console.error('Updated changelog: ' + changelogPath);
                }
              }
            }
          }

          // Second pass: Sync internal dependencies across ALL publishable packages
          // If a package depends on a bumped package, update the dep version and patch-bump the dependent
          const { execSync } = require('child_process');
          let allLibs = [];
          try {
            const allPublishable = execSync('npx nx show projects -p tag:scope:publishable --type lib --json', { encoding: 'utf8' });
            allLibs = JSON.parse(allPublishable);
          } catch (e) {
            console.error('Warning: Could not get publishable libs for dependency sync');
          }

          for (const libName of allLibs) {
            const pkgPath = 'libs/' + libName + '/package.json';
            if (!fs.existsSync(pkgPath)) continue;

            const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf8'));
            let modified = false;
            let needsBump = false;

            // Check if any internal dependency was bumped
            // Only update exact-pinned versions (internal deps), skip range specifiers (external deps)
            if (pkg.dependencies) {
              for (const [dep, version] of Object.entries(pkg.dependencies)) {
                if (internalVersions[dep] && isExactVersion(version) && version !== internalVersions[dep]) {
                  pkg.dependencies[dep] = internalVersions[dep];
                  modified = true;
                  needsBump = true;
                  console.error('Updated ' + libName + ' dep ' + dep + ' to ' + internalVersions[dep]);
                }
              }
            }

            // If this package wasn't already bumped but has updated deps, patch bump it
            if (needsBump && !internalVersions[libName]) {
              const newVersion = bumpPatch(pkg.version);
              pkg.version = newVersion;
              internalVersions[libName] = newVersion;
              bumpedProjects.push(libName);
              console.error('Patch bumped ' + libName + ' to ' + newVersion + ' (dependency update)');

              // Update max version
              if (newVersion.localeCompare(maxVersion, undefined, { numeric: true, sensitivity: 'base' }) > 0) {
                maxVersion = newVersion;
              }
            }

            if (modified) {
              fs.writeFileSync(pkgPath, JSON.stringify(pkg, null, 2) + '\n');
            }
          }

          // Update global changelog
          if (output.globalChangelog && bumpedProjects.length > 0) {
            const globalPath = 'CHANGELOG.md';
            if (fs.existsSync(globalPath)) {
              let content = fs.readFileSync(globalPath, 'utf8');

              // Build global entry
              let globalEntry = '## [' + maxVersion + '] - ' + today + '\n\n';
              globalEntry += output.globalChangelog.summary + '\n\n';
              globalEntry += '### Updated Libraries\n\n';
              for (const p of output.globalChangelog.projects) {
                globalEntry += '- **' + p.name + '** v' + p.version + ' - ' + p.summary + '\n';
              }

              // Insert after ## [Unreleased] section
              const unreleasedMatch = content.match(/## \[Unreleased\]\n*/);
              if (unreleasedMatch) {
                const insertPos = unreleasedMatch.index + unreleasedMatch[0].length;
                content = content.slice(0, insertPos) + '\n' + globalEntry + '\n' + content.slice(insertPos);
              }
              fs.writeFileSync(globalPath, content);
              console.error('Updated global changelog');
            }
          }

          // Log docs update summary
          if (output.docs && output.docs.updated) {
            console.error('Documentation updated: ' + output.docs.summary);
            console.error('Files modified: ' + output.docs.files.join(', '));
          }

          // Output for GitHub Actions
          console.log(JSON.stringify({ maxVersion, bumpedProjects: bumpedProjects.join(',') }));
          NODEJS_SCRIPT
          )

          MAX_VERSION=$(echo "$RESULT" | jq -r '.maxVersion')
          BUMPED=$(echo "$RESULT" | jq -r '.bumpedProjects')

          echo "max_version=$MAX_VERSION" >> "$GITHUB_OUTPUT"
          echo "bumped_projects=$BUMPED" >> "$GITHUB_OUTPUT"

          echo "Max version: $MAX_VERSION"
          echo "Bumped projects: $BUMPED"

      - name: Log release analysis result
        if: steps.affected.outputs.projects != ''
        shell: bash
        run: |
          if [ -f "${{ env.CODEX_OUTPUT }}" ]; then
            echo "Release analysis result:"
            cat "${{ env.CODEX_OUTPUT }}"

            # Extract and display docs summary
            DOCS_UPDATED=$(node -e "const o = require('./${{ env.CODEX_OUTPUT }}'); console.log(o.docs?.updated || false)")
            if [ "$DOCS_UPDATED" = "true" ]; then
              echo ""
              echo "Documentation was updated:"
              node -e "const o = require('./${{ env.CODEX_OUTPUT }}'); console.log('  Summary: ' + o.docs.summary); console.log('  Files: ' + o.docs.files.join(', '))"
            else
              echo "No documentation updates were made"
            fi
          fi

      - name: Create release branch
        id: branch
        if: steps.versions.outputs.bumped_projects != ''
        shell: bash
        run: |
          set -euo pipefail

          MAX_VERSION="${{ steps.versions.outputs.max_version }}"
          BRANCH_NAME="next/$MAX_VERSION"

          git fetch origin main --tags
          git switch -c "$BRANCH_NAME" origin/main

          echo "branch_name=$BRANCH_NAME" >> "$GITHUB_OUTPUT"
          echo "Created branch: $BRANCH_NAME"

      - name: Commit version bumps and docs
        if: steps.versions.outputs.bumped_projects != ''
        shell: bash
        run: |
          set -euo pipefail

          MAX_VERSION="${{ steps.versions.outputs.max_version }}"
          BUMPED="${{ steps.versions.outputs.bumped_projects }}"

          if [ -n "$(git status --porcelain)" ]; then
            git add -A
            git commit -m "chore(release): prepare release v$MAX_VERSION" \
              -m "Bumped versions for: $BUMPED" \
              -m "Version analysis and docs updates by Codex AI."
            echo "Created release preparation commit"
          else
            echo "No changes to commit"
            git commit --allow-empty -m "chore(release): prepare release v$MAX_VERSION"
          fi

      - name: Push branch
        if: steps.versions.outputs.bumped_projects != ''
        shell: bash
        run: |
          set -euo pipefail
          BRANCH_NAME="${{ steps.branch.outputs.branch_name }}"
          git push --set-upstream origin "$BRANCH_NAME"

      - name: Create PR
        if: steps.versions.outputs.bumped_projects != ''
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        shell: bash
        run: |
          set -euo pipefail

          MAX_VERSION="${{ steps.versions.outputs.max_version }}"
          BUMPED="${{ steps.versions.outputs.bumped_projects }}"
          BRANCH_NAME="${{ steps.branch.outputs.branch_name }}"
          BASE="main"
          TITLE="Release v$MAX_VERSION"

          # Check for existing PR
          EXISTING_PR=$(gh pr list \
            --base "$BASE" \
            --head "$BRANCH_NAME" \
            --state open \
            --json number \
            --jq '.[0].number' || echo "")

          if [ -n "$EXISTING_PR" ]; then
            echo "PR #$EXISTING_PR already exists"
            exit 0
          fi

          # Create PR body
          BODY=$(cat <<EOF
          ## Release v$MAX_VERSION

          ### Projects to publish
          $(echo "$BUMPED" | tr ',' '\n' | sed 's/^/- /')

          ### Version analysis
          Versions determined by Codex AI based on semantic analysis of code changes.

          ### Documentation
          Documentation updates included if applicable.

          ---
          Merge this PR to publish the affected packages to npm.
          EOF
          )

          gh pr create \
            --base "$BASE" \
            --head "$BRANCH_NAME" \
            --title "$TITLE" \
            --body "$BODY"

      - name: Upload artifacts (debug)
        uses: actions/upload-artifact@v4
        with:
          name: codex-release-artifacts
          path: |
            .codex-release/**
            .github/codex/prompts/**

      - name: Summary
        run: |
          echo "## Release Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** ${{ steps.branch.outputs.branch_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Max Version:** ${{ steps.versions.outputs.max_version }}" >> $GITHUB_STEP_SUMMARY
          echo "**Projects:** ${{ steps.versions.outputs.bumped_projects }}" >> $GITHUB_STEP_SUMMARY
          echo "**First Release:** ${{ steps.last_release.outputs.is_first_release }}" >> $GITHUB_STEP_SUMMARY
          echo "**Analysis:** Codex AI (gpt-5.1-codex)" >> $GITHUB_STEP_SUMMARY
